# Trabalho Final de FIA: Racioc√≠nio Espacial Neuro-Simb√≥lico com LTNtorch

**Disciplina:** Fundamentos de Intelig√™ncia Artificial
**Ferramenta:** Logic Tensor Networks (LTNtorch)

### üë®‚Äçüíª Integrantes do Grupo

* Bruno Jos√© dos Santos de Melo 
* Isaque Gomes da Costa Filho
* Jo√£o Ricardo dos Santos Neto 
* Jo√£o Victor Bastos Pinheiro
* Matheus Ricardo Oliveira Lima 
* Rodrigo de Souza Cunha
* Sara Oliveira dos Santos
* Vin√≠cius Matheus N. de Oliveira

---

## 1. Descri√ß√£o Te√≥rica

### 1.1. Intelig√™ncia Artificial Neuro-Simb√≥lica (NeSy)
A **IA Neuro-Simb√≥lica (NeSy)** combina o aprendizado robusto de redes neurais (Deep Learning) com a capacidade de racioc√≠nio e explicabilidade da l√≥gica simb√≥lica. Enquanto as redes neurais s√£o excelentes para lidar com dados sensoriais e incerteza, a l√≥gica fornece a estrutura para raciocinar sobre esses dados, permitindo sistemas que aprendem com menos dados e respeitam regras de conhecimento pr√©vio.

### 1.2. Logic Tensor Networks (LTN)
O projeto utiliza **Logic Tensor Networks (LTN)**, uma estrutura que integra l√≥gica de primeira ordem em redes profundas.
* **Predicados** (ex: `IsCircle(x)`) s√£o redes neurais que retornam um grau de verdade $[0,1]$.
* **Axiomas** s√£o f√≥rmulas l√≥gicas usadas na fun√ß√£o de perda (Loss). O treinamento busca maximizar a satisfatibilidade ($\text{SatAgg}$) dessas f√≥rmulas.

### 1.3. O Dataset CLEVR Simplificado
Foi simulado um ambiente com objetos definidos por vetores de caracter√≠sticas de 11 posi√ß√µes:
* **Posi√ß√£o [0-1]:** Coordenadas x, y.
* **Cor [2-4]:** One-hot encoding (RGB).
* **Forma [5-9]:** One-hot encoding (C√≠rculo, Quadrado, Cilindro, Cone, Tri√¢ngulo).
* **Tamanho [10]:** Valor cont√≠nuo (0.0 a 1.0).

---

## 2. Experimentos e M√©tricas

O sistema foi avaliado em **5 execu√ß√µes independentes**, gerando novos datasets aleat√≥rios a cada rodada. O objetivo foi medir a capacidade do modelo de satisfazer regras l√≥gicas e responder a consultas complexas.

### 2.1. F√≥rmulas Avaliadas (Passo 3.3)

1.  **Q1 (Filtragem Composta):** $\exists x(IsSmall(x)\wedge\exists y(IsCylinder(y)\wedge Below(x,y))\wedge\exists z(IsSquare(z)\wedge LeftOf(x,z)))$
    * *Significado:* Busca se existe um objeto pequeno, abaixo de um cilindro e √† esquerda de um quadrado.
2.  **Q2 (Dedu√ß√£o Espacial):** $\exists x,y,z(IsCone(x)\wedge IsGreen(x)\wedge InBetween(x,y,z))$
    * *Significado:* Pergunta se existe um Cone Verde posicionado entre dois outros objetos. A rela√ß√£o `InBetween` √© deduzida logicamente das rela√ß√µes `LeftOf`/`RightOf`.
3.  **Regra de Proximidade:** $\forall x,y((IsTriangle(x)\wedge IsTriangle(y)\wedge CloseTo(x,y))\Rightarrow SameSize(x,y))$
    * *Significado:* Regra universal que imp√µe que dois tri√¢ngulos pr√≥ximos devem ter o mesmo tamanho.

---

## 3. Resultados Consolidados

Abaixo est√£o as m√©dias e desvios padr√£o obtidos ap√≥s as 5 execu√ß√µes do experimento.

| M√©trica | M√©dia | Desvio Padr√£o ($\sigma$) | An√°lise |
| :--- | :--- | :--- | :--- |
| **Satisfa√ß√£o Q1** | 0.0002 | 0.0000 | Baixa satisfa√ß√£o esperada, pois a configura√ß√£o espec√≠fica raramente ocorre em dados aleat√≥rios. |
| **Satisfa√ß√£o Q2** | 0.0002 | 0.0000 | Similar √† Q1, a combina√ß√£o "Cone Verde" + "Posi√ß√£o Entre" √© rara estocasticamente. |
| **Sat. Regra Proximidade** | **0.9181** | 0.0244 | **Alta.** O modelo aprendeu a correlacionar a proximidade espacial com a igualdade de tamanho para tri√¢ngulos, mantendo consist√™ncia acima de 91%. |
| **Acur√°cia (Formas)** | **1.0000** | 0.0000 | **Perfeita.** O modelo identificou corretamente todas as formas geom√©tricas. |
| **Precis√£o** | **1.0000** | 0.0000 | Nenhuma predi√ß√£o falso-positiva foi observada nas formas. |
| **Recall** | **1.0000** | 0.0000 | O modelo recuperou todas as inst√¢ncias corretas de cada classe. |
| **F1 Score** | **1.0000** | 0.0000 | Desempenho m√°ximo na classifica√ß√£o. |

### 3.1. Explica√ß√£o do Racioc√≠nio (Ponto Extra)
O experimento demonstra que o LTN √© capaz de:
1.  Realizar **Grounding Simb√≥lico** perfeito (F1 Score = 1.0), mapeando caracter√≠sticas num√©ricas para conceitos l√≥gicos sem erro.
2.  Incorporar **Conhecimento Abstrato** (`sat_regra_prox` > 0.9), impondo restri√ß√µes l√≥gicas no aprendizado.
3.  Avaliar **Consultas Existenciais** (Q1/Q2) de forma difusa (fuzzy), retornando valores consistentes com a aleatoriedade dos dados.

---

## 4. Como Executar

1. Instalar depend√™ncias: `pip install git+https://github.com/logictensornetworks/LTNtorch`
2. Executar o script `main.py` (ou notebook).
