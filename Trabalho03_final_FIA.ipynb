{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ltn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# --- 1. CONFIGURAÇÃO ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Rodando em: {device}\")\n",
        "\n",
        "# --- 2. GERAÇÃO DE DADOS (CLEVR SIMPLIFICADO) ---\n",
        "class ClevrSimplified:\n",
        "    def __init__(self, num_samples=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.data = self._generate()\n",
        "\n",
        "    def _generate(self):\n",
        "        data = []\n",
        "        for _ in range(self.num_samples):\n",
        "            pos = np.random.rand(2) # [0,1]\n",
        "            c_idx = np.random.randint(0, 3)\n",
        "            color = np.zeros(3); color[c_idx] = 1 # [2,3,4]\n",
        "            s_idx = np.random.randint(0, 5)\n",
        "            shape = np.zeros(5); shape[s_idx] = 1 # [5,6,7,8,9]\n",
        "            is_large = np.random.rand() > 0.5\n",
        "            size = np.array([1.0 if is_large else 0.0]) # [10]\n",
        "            vec = np.concatenate([pos, color, shape, size])\n",
        "            data.append(vec)\n",
        "        return torch.tensor(np.array(data), dtype=torch.float32).to(device)\n",
        "\n",
        "# --- 3. MODELOS NEURAIS ---\n",
        "# Modelos para características (Shapes, Colors, Size)\n",
        "class FeatureModel(nn.Module):\n",
        "    def __init__(self, input_indices):\n",
        "        super(FeatureModel, self).__init__()\n",
        "        self.indices = input_indices\n",
        "        input_dim = len(input_indices)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16), nn.ELU(), nn.Linear(16, 1), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x[..., self.indices])\n",
        "\n",
        "# Modelos para Relações (Spatial)\n",
        "class RelationModel(nn.Module):\n",
        "    def __init__(self, axis_idx):\n",
        "        super(RelationModel, self).__init__()\n",
        "        self.axis = axis_idx\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 16), nn.ELU(), nn.Linear(16, 1), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x, y):\n",
        "        # Pega a coordenada específica (X=0 ou Y=1) de ambos os objetos\n",
        "        return self.net(torch.cat([x[..., self.axis:self.axis+1], y[..., self.axis:self.axis+1]], dim=-1))\n",
        "\n",
        "# Modelos Fixos (Matemáticos)\n",
        "class CloseToModel(nn.Module):\n",
        "    def forward(self, x, y):\n",
        "        dist_sq = torch.sum((x[..., 0:2] - y[..., 0:2])**2, dim=-1, keepdim=True)\n",
        "        return torch.exp(-2.0 * dist_sq)\n",
        "\n",
        "class SameSizeModel(nn.Module):\n",
        "    def forward(self, x, y):\n",
        "        return 1.0 - torch.abs(x[..., 10:11] - y[..., 10:11])\n",
        "\n",
        "# --- 4. FUNÇÃO PRINCIPAL DE EXECUÇÃO (Loop de 5x) ---\n",
        "def run_experiment(run_id):\n",
        "    print(f\"\\n--- INICIANDO EXECUÇÃO {run_id+1}/5 ---\")\n",
        "\n",
        "    # A. Instanciar Predicados (Reiniciando pesos a cada run)\n",
        "    # Formas (indices 5 a 9)\n",
        "    IsCircle = ltn.Predicate(FeatureModel([5]).to(device))\n",
        "    IsSquare = ltn.Predicate(FeatureModel([6]).to(device))\n",
        "    IsCylinder = ltn.Predicate(FeatureModel([7]).to(device))\n",
        "    IsCone = ltn.Predicate(FeatureModel([8]).to(device))\n",
        "    IsTriangle = ltn.Predicate(FeatureModel([9]).to(device))\n",
        "\n",
        "    # Cores (2 a 4) e Tamanho (10)\n",
        "    IsGreen = ltn.Predicate(FeatureModel([3]).to(device))\n",
        "    IsSmall = ltn.Predicate(FeatureModel([10]).to(device)) # Assumindo 0=Small no treino, mas o feature é 0 ou 1\n",
        "    # Nota: Se 0.0 é pequeno, a rede precisa aprender a inverter ou mapear 0->High.\n",
        "    # Para facilitar, IsSmall pode ser Not(IsBig) ou treinado direto.\n",
        "\n",
        "    # Relações\n",
        "    LeftOf = ltn.Predicate(RelationModel(0).to(device)) # Eixo X\n",
        "    RightOf = ltn.Predicate(RelationModel(0).to(device))\n",
        "    Below = ltn.Predicate(RelationModel(1).to(device)) # Eixo Y\n",
        "    Above = ltn.Predicate(RelationModel(1).to(device))\n",
        "\n",
        "    CloseTo = ltn.Predicate(CloseToModel().to(device))\n",
        "    SameSize = ltn.Predicate(SameSizeModel().to(device))\n",
        "\n",
        "    # Operadores\n",
        "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
        "    And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
        "    Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
        "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
        "    Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
        "    Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
        "    sat_agg = ltn.fuzzy_ops.AggregPMeanError(p=2)\n",
        "\n",
        "    # B. Dados e Variáveis\n",
        "    ds = ClevrSimplified(num_samples=60) # Um pouco mais de dados\n",
        "    data = ds.data\n",
        "    x = ltn.Variable(\"x\", data)\n",
        "    y = ltn.Variable(\"y\", data)\n",
        "    z = ltn.Variable(\"z\", data)\n",
        "\n",
        "    # C. Otimizador\n",
        "    optimizer = torch.optim.Adam(\n",
        "        list(IsCircle.parameters()) + list(IsSquare.parameters()) +\n",
        "        list(IsCylinder.parameters()) + list(IsCone.parameters()) + list(IsTriangle.parameters()) +\n",
        "        list(IsSmall.parameters()) + list(IsGreen.parameters()) +\n",
        "        list(LeftOf.parameters()) + list(RightOf.parameters()) +\n",
        "        list(Below.parameters()) + list(Above.parameters()), lr=0.01\n",
        "    )\n",
        "\n",
        "    # D. Loop de Treino\n",
        "    print(\"Treinando...\")\n",
        "    for epoch in range(300): # 300 épocas é suficiente para esse problema simples\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # --- AXIOMAS ---\n",
        "\n",
        "        # 1. Taxonomia Completa (Um objeto deve ser uma e apenas uma forma)\n",
        "        # Cobertura: É Círculo OU Quadrado OU Cilindro OU Cone OU Triângulo\n",
        "        sat_cov = Forall(x, Or(Or(Or(Or(IsCircle(x), IsSquare(x)), IsCylinder(x)), IsCone(x)), IsTriangle(x)))\n",
        "\n",
        "        # Exclusão Mútua (Exemplo par a par para simplificar código, ou lógica geral)\n",
        "        # Forma simplificada: Se é Círculo, não pode ser Quadrado, etc.\n",
        "        sat_mut_1 = Forall(x, Implies(IsCircle(x), Not(IsSquare(x))))\n",
        "        sat_mut_2 = Forall(x, Implies(IsSquare(x), Not(IsCylinder(x)))) # Adicionar mais pares idealmente\n",
        "\n",
        "        # 2. Espacial (LeftOf/RightOf)\n",
        "        sat_lr_irref = Forall(x, Not(LeftOf(x, x)))\n",
        "        sat_lr_inv = Forall([x, y], Implies(LeftOf(x, y), RightOf(y, x)))\n",
        "        sat_lr_trans = Forall([x,y,z], Implies(And(LeftOf(x,y), LeftOf(y,z)), LeftOf(x,z))) # TRANSITIVIDADE\n",
        "\n",
        "        # 3. Vertical (Below/Above)\n",
        "        sat_ud_inv = Forall([x, y], Implies(Below(x, y), Above(y, x)))\n",
        "        sat_ud_trans = Forall([x,y,z], Implies(And(Below(x,y), Below(y,z)), Below(x,z))) # TRANSITIVIDADE\n",
        "\n",
        "        # 4. Supervisão (Grounding Simples para ancorar os conceitos)\n",
        "        # Usamos máscaras reais do dataset para ensinar o que é o que\n",
        "        mask_circ = data[:, 5] == 1\n",
        "        mask_sq = data[:, 6] == 1\n",
        "        mask_cyl = data[:, 7] == 1\n",
        "        mask_cone = data[:, 8] == 1\n",
        "        mask_tri = data[:, 9] == 1\n",
        "\n",
        "        # Se houver dados dessa classe, ensina. Senão, ignora (Constant 1.0)\n",
        "        s_circ = Forall(ltn.Variable(\"xc\", data[mask_circ]), IsCircle(ltn.Variable(\"xc\", data[mask_circ]))) if mask_circ.any() else ltn.Constant(1.)\n",
        "        s_sq = Forall(ltn.Variable(\"xs\", data[mask_sq]), IsSquare(ltn.Variable(\"xs\", data[mask_sq]))) if mask_sq.any() else ltn.Constant(1.)\n",
        "        s_cyl = Forall(ltn.Variable(\"xcy\", data[mask_cyl]), IsCylinder(ltn.Variable(\"xcy\", data[mask_cyl]))) if mask_cyl.any() else ltn.Constant(1.)\n",
        "        s_cone = Forall(ltn.Variable(\"xco\", data[mask_cone]), IsCone(ltn.Variable(\"xco\", data[mask_cone]))) if mask_cone.any() else ltn.Constant(1.)\n",
        "        s_tri = Forall(ltn.Variable(\"xt\", data[mask_tri]), IsTriangle(ltn.Variable(\"xt\", data[mask_tri]))) if mask_tri.any() else ltn.Constant(1.)\n",
        "\n",
        "        # Agregação da Loss\n",
        "        sat_total = sat_agg(torch.stack([\n",
        "            sat_cov.value, sat_mut_1.value, sat_mut_2.value,\n",
        "            sat_lr_irref.value, sat_lr_inv.value, sat_lr_trans.value,\n",
        "            sat_ud_inv.value, sat_ud_trans.value,\n",
        "            s_circ.value, s_sq.value, s_cyl.value, s_cone.value, s_tri.value\n",
        "        ]))\n",
        "\n",
        "        loss = 1.0 - sat_total\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Loss Final Run {run_id+1}: {loss.item():.4f}\")\n",
        "\n",
        "    # --- 5. AVALIAÇÃO E CONSULTAS ---\n",
        "\n",
        "    # A. Predicado 'canStack' (Tarefa 3)\n",
        "    # Regra: Pode empilhar se Y NÃO for Cone E NÃO for Triângulo\n",
        "    # Aqui definimos como uma fórmula composta, não predicado treinado, pois deriva de formas\n",
        "    def canStack(obj_x, obj_y):\n",
        "        # obj_x sobre obj_y. Regra depende de Y.\n",
        "        return And(Not(IsCone(obj_y)), Not(IsTriangle(obj_y)))\n",
        "\n",
        "    # B. Consultas Complexas (Tarefa 4)\n",
        "    # Q1: Objeto Pequeno, Abaixo de Cilindro e Esq de Quadrado\n",
        "    q1 = Exists(x, And(IsSmall(x), And(Exists(y, And(IsCylinder(y), Below(x,y))), Exists(z, And(IsSquare(z), LeftOf(x,z))))))\n",
        "\n",
        "    # Q2: Cone Verde Entre dois objetos\n",
        "    # InBetween(x,y,z) = (LeftOf(y,x) & RightOf(z,x)) OR ... Simplificado para LeftOf(y,x) & LeftOf(x,z)\n",
        "    q2 = Exists([x,y,z], And(And(IsCone(x), IsGreen(x)), And(LeftOf(y,x), LeftOf(x,z))))\n",
        "\n",
        "    # C. Cálculo de Métricas (Shape Classification)\n",
        "    true_shapes = torch.argmax(data[:, 5:10], dim=1).cpu().numpy()\n",
        "\n",
        "    # Forward em todos os predicados de forma\n",
        "    p_s = []\n",
        "    for pred in [IsCircle, IsSquare, IsCylinder, IsCone, IsTriangle]:\n",
        "        p_s.append(pred.model(data).detach().cpu().numpy())\n",
        "    pred_shapes = np.argmax(np.stack(p_s, axis=1).squeeze(), axis=1)\n",
        "\n",
        "    acc = accuracy_score(true_shapes, pred_shapes)\n",
        "    prec = precision_score(true_shapes, pred_shapes, average='macro', zero_division=0)\n",
        "    rec = recall_score(true_shapes, pred_shapes, average='macro', zero_division=0)\n",
        "    f1 = f1_score(true_shapes, pred_shapes, average='macro', zero_division=0)\n",
        "\n",
        "    # Retorna dicionário de resultados\n",
        "    return {\n",
        "        \"sat_q1\": q1.value.item(),\n",
        "        \"sat_q2\": q2.value.item(),\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "# --- 6. EXECUÇÃO DOS 5 EXPERIMENTOS ---\n",
        "results = []\n",
        "for i in range(5):\n",
        "    res = run_experiment(i)\n",
        "    results.append(res)\n",
        "\n",
        "# --- 7. RELATÓRIO FINAL ---\n",
        "print(\"\\n=== RESULTADOS FINAIS (MÉDIA DE 5 EXECUÇÕES) ===\")\n",
        "keys = results[0].keys()\n",
        "for k in keys:\n",
        "    values = [r[k] for r in results]\n",
        "    mean_val = np.mean(values)\n",
        "    std_val = np.std(values)\n",
        "    print(f\"{k}: {mean_val:.4f} (+/- {std_val:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfvMvpD8GkPf",
        "outputId": "0f92edeb-c49f-44bf-ffc1-db373a19f5af"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando em: cpu\n",
            "\n",
            "--- INICIANDO EXECUÇÃO 1/5 ---\n",
            "Treinando...\n",
            "Loss Final Run 1: 0.0008\n",
            "\n",
            "--- INICIANDO EXECUÇÃO 2/5 ---\n",
            "Treinando...\n",
            "Loss Final Run 2: 0.0009\n",
            "\n",
            "--- INICIANDO EXECUÇÃO 3/5 ---\n",
            "Treinando...\n",
            "Loss Final Run 3: 0.0007\n",
            "\n",
            "--- INICIANDO EXECUÇÃO 4/5 ---\n",
            "Treinando...\n",
            "Loss Final Run 4: 0.0008\n",
            "\n",
            "--- INICIANDO EXECUÇÃO 5/5 ---\n",
            "Treinando...\n",
            "Loss Final Run 5: 0.0007\n",
            "\n",
            "=== RESULTADOS FINAIS (MÉDIA DE 5 EXECUÇÕES) ===\n",
            "sat_q1: 0.0001 (+/- 0.0000)\n",
            "sat_q2: 0.0001 (+/- 0.0000)\n",
            "accuracy: 1.0000 (+/- 0.0000)\n",
            "precision: 1.0000 (+/- 0.0000)\n",
            "recall: 1.0000 (+/- 0.0000)\n",
            "f1: 1.0000 (+/- 0.0000)\n"
          ]
        }
      ]
    }
  ]
}